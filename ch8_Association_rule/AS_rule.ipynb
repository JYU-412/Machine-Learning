{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 9. Finding Patterns – Market Basket Analysis Using Association Rules\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning has been increasingly applied to learn purchasing patterns. The practice is commonly known as **market basket analysis** due to the fact that it has been so frequently applied to supermarket data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding association rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The building blocks of a market basket analysis are the items that may appear in any given transaction. Groups of one or more items are surrounded by brackets to indicate that they form a set, or more specifically, an itemset that appears in the data with some regularity. Transactions are specified in terms of itemsets, such as the following transaction that might be found in a typical grocery store:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\{bread, peanut butter, jelly\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of a market basket analysis is a collection of association rules that specify patterns found in the relationships among items. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Association rules are always composed from subsets of itemsets and are denoted by relating one itemset on the left-hand side (LHS) of the rule to another itemset on the right-hand side (RHS) of the rule. The LHS is the condition that needs to be met in order to trigger the rule, and the RHS is the expected result of meeting that condition. A rule identified from the example transaction might be expressed in the form:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\{bread, peanut butter\\}\\rightarrow \\{jelly\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In plain language, this association rule states that if peanut butter and jelly are purchased together, then bread is also likely to be purchased. In other words, \"peanut butter and jelly imply bread.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The association rule learners are unsupervised, there is no need for the algorithm to be trained; data does not need to be labeled ahead of time. Association rules are not used for prediction, but are closely related to and share many features of the classification rule learners such as decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other potential applications include:\n",
    "\n",
    "- Searching for interesting and frequently occurring patterns of DNA and protein sequences in cancer data\n",
    "- Finding patterns of purchases or medical claims that occur in combination with fraudulent credit card or insurance use\n",
    "- Identifying combinations of behavior that precede customers dropping their cellular phone service or upgrading their cable television package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Apriori algorithm for association rule learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transactional datasets are typically extremely large, both in terms of the number of transactions as well as the number of items or features that are monitored. The problem is that the number of potential itemsets grows exponentially with the number of features. Given k items that can appear or not appear in a set, there are $2^k$ possible itemsets that could be potential rules. A retailer that sells only 100 different items could have on the order of $2^{100} = 1.27e{30}$ itemsets that an algorithm must evaluate—a seemingly impossible task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In reality, many of the potential combinations of items are rarely, if ever, found in practice. For instance, a set of $\\{motor oil, lipstick\\}$ is likely to be extraordinarily uncommon. By ignoring these rare (and, perhaps, less important) combinations, it is possible to limit the scope of the search for rules to a more manageable size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the Apriori algorithm has become somewhat synonymous with association rule learning. The name is derived from the fact that the algorithm utilizes a simple prior (that is, a priori) belief about the properties of frequent itemsets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strengths\n",
    "- Is capable of working with large amounts of transactional data\n",
    "- Results in rules that are easy to understand\n",
    "- Useful for \"data mining\" and discovering unexpected knowledge in databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weaknesses\n",
    "\n",
    "- Not very helpful for small datasets\n",
    "- Requires effort to separate the true insight from common sense\n",
    "- Easy to draw spurious conclusions from random patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noted earlier, the Apriori algorithm employs a simple a priori belief to reduce the association rule search space: all subsets of a frequent itemset must also be frequent. This heuristic is known as the **Apriori property**. Because $\\{motor oil, lipstick\\}$ is rare, if either motor oil or lipstick is infrequent, any set containing these items can be excluded from the search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table shows five completed transactions in an imaginary hospital's gift shop:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Transaction number | Sweetness                                      |\n",
    "|--------------------|------------------------------------------------|\n",
    "| 1                  | {flowers, get well card, soda}                 |\n",
    "| 2                  | {plush toy bear, flowers, balloons, candy bar} |\n",
    "| 3                  | {get well card, candy bar, flowers}            |\n",
    "| 4                  | {plush toy bear, balloons, soda}               |\n",
    "| 5                  | {flowers, get well card, soda}                 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple of typical buying patterns. A person visiting a sick friend or family member tends to buy a get well card and flowers, while visitors to new mothers tend to buy plush toy bears and balloons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a similar fashion, the Apriori algorithm uses statistical measures of an itemset's \"interestingness\" to locate association rules in much larger transaction databases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring rule interest – support and confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whether or not an association rule is deemed interesting is determined by two statistical measures: support and confidence measures. By providing minimum thresholds for each of these metrics and applying the Apriori principle, it is easy to drastically limit the number of rules reported, perhaps even to the point where only the obvious or common sense rules are identified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **support** of an itemset or rule measures how frequently it occurs in the data. For instance the itemset $\\{get well card, flowers\\}$, has support of 3 / 5 = 0.6 in the hospital gift shop data. Similarly, the support for $\\{get well card\\}$ → $\\{flowers\\}$ is also 0.6. A function defining support for the itemset X can be defined as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$support(X)= \\frac{count(X)}{N}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, N is the number of transactions in the database and count(X) is the number of transactions containing itemset X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A rule's **confidence** is a measurement of its predictive power or accuracy. It is defined as the support of the itemset containing both X and Y divided by the support of the itemset containing only X:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$confidence(X \\rightarrow Y)= \\frac{support(X,Y)}{support(X)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially, the confidence tells us the proportion of transactions where the presence of item or itemset X results in the presence of item or itemset Y. Keep in mind that the confidence that X leads to Y is not the same as the confidence that Y leads to X. For example, the confidence of {flowers} → {get well card} is 0.6 / 0.8 = 0.75. In comparison, the confidence of {get well card} → {flowers} is 0.6 / 0.6 = 1.0. This means that a purchase involving flowers is accompanied by a purchase of a get well card 75 percent of the time, while a purchase of a get well card is associated with flowers 100 percent of the time. This information could be quite useful to the gift shop management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rules like {get well card} → {flowers} are known as **strong rules**, because they have both high support and confidence. Next, you will see how the Apriori algorithm uses the minimum levels of support and confidence with the Apriori principle to find strong rules quickly by reducing the number of rules to a more manageable level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Building a set of rules with the Apriori principle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the Apriori principle states that all subsets of a frequent itemset must also be frequent. In other words, if {A, B} is frequent, then {A} and {B} must both be frequent. Recall also that by definition, the support indicates how frequently an itemset appears in the data. Therefore, if we know that {A} does not meet a desired support threshold, there is no reason to consider {A, B} or any itemset containing {A}; it cannot possibly be frequent. The actual process of creating rules occurs in two phases:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. dentifying all the itemsets that meet a minimum support threshold.\n",
    "2. Creating rules from these itemsets using those meeting a minimum confidence threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first phase occurs in multiple iterations. Each successive iteration involves evaluating the support of a set of increasingly large itemsets. For instance, iteration 1 involves evaluating the set of 1-item itemsets (1-itemsets), iteration 2 evaluates 2-itemsets, and so on. The result of each iteration $i$ is a set of all the $i$-itemsets that meet the minimum support threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the itemsets from iteration $i$ are combined in order to generate candidate itemsets for the evaluation in iteration $i$ + 1. But the Apriori principle can eliminate some of them even before the next round begins. If {A}, {B}, and {C} are frequent in iteration 1 while {D} is not frequent, iteration 2 will consider only {A, B}, {A, C}, and {B, C}. Thus, the algorithm needs to evaluate only three itemsets rather than the six that would have been evaluated if the sets containing D had not been eliminated a priori."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuing with this thought, suppose during iteration 2, it is discovered that {A, B} and {B, C} are frequent, but {A, C} is not. Although iteration 3 would normally begin by evaluating the support for {A, B, C}, it is not mandatory that this step should occur at all. Why not? The Apriori principle states that {A, B, C} cannot possibly be frequent, since the subset {A, C} is not. Therefore, having generated no new itemsets in iteration 3, the algorithm may stop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, the second phase of the Apriori algorithm may begin. Given the set of frequent itemsets, association rules are generated from all possible subsets. For instance, {A, B} would result in candidate rules for {A} → {B} and {B} → {A}. These are evaluated against a minimum confidence threshold, and any rule that does not meet the desired confidence level is eliminated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An example of a list of 20 orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas  as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from efficient_apriori import apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>toothpaste</td>\n",
       "      <td>brush</td>\n",
       "      <td>milk</td>\n",
       "      <td>cereals</td>\n",
       "      <td>honey</td>\n",
       "      <td>bread</td>\n",
       "      <td>butter</td>\n",
       "      <td>cheese</td>\n",
       "      <td>yogurt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>milk</td>\n",
       "      <td>cereals</td>\n",
       "      <td>honey</td>\n",
       "      <td>bread</td>\n",
       "      <td>cheese</td>\n",
       "      <td>razor</td>\n",
       "      <td>gel</td>\n",
       "      <td>shampoo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>milk</td>\n",
       "      <td>cereals</td>\n",
       "      <td>honey</td>\n",
       "      <td>cheese</td>\n",
       "      <td>soap</td>\n",
       "      <td>shampoo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>honey</td>\n",
       "      <td>bread</td>\n",
       "      <td>butter</td>\n",
       "      <td>cheese</td>\n",
       "      <td>mouthwash</td>\n",
       "      <td>toothpaste</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cereals</td>\n",
       "      <td>honey</td>\n",
       "      <td>bread</td>\n",
       "      <td>butter</td>\n",
       "      <td>gel</td>\n",
       "      <td>soap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cheesse</td>\n",
       "      <td>yogurt</td>\n",
       "      <td>milk</td>\n",
       "      <td>cereals</td>\n",
       "      <td>honey</td>\n",
       "      <td>shampoo</td>\n",
       "      <td>gel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>honey</td>\n",
       "      <td>bread</td>\n",
       "      <td>cheese</td>\n",
       "      <td>razor</td>\n",
       "      <td>butter</td>\n",
       "      <td>yogurt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>honey</td>\n",
       "      <td>bread</td>\n",
       "      <td>cheese</td>\n",
       "      <td>butter</td>\n",
       "      <td>milk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cereals</td>\n",
       "      <td>butter</td>\n",
       "      <td>cookies</td>\n",
       "      <td>chips</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cerals</td>\n",
       "      <td>cheese</td>\n",
       "      <td>yogurt</td>\n",
       "      <td>cookies</td>\n",
       "      <td>chips</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>toothpaste</td>\n",
       "      <td>brush</td>\n",
       "      <td>gel</td>\n",
       "      <td>shampoo</td>\n",
       "      <td>soap</td>\n",
       "      <td>cookies</td>\n",
       "      <td>chips</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>toothpaste</td>\n",
       "      <td>brush</td>\n",
       "      <td>gel</td>\n",
       "      <td>razor</td>\n",
       "      <td>mouthwash</td>\n",
       "      <td>milk</td>\n",
       "      <td>cookies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>razor</td>\n",
       "      <td>shampoo</td>\n",
       "      <td>gel</td>\n",
       "      <td>soap</td>\n",
       "      <td>bread</td>\n",
       "      <td>butter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>brush</td>\n",
       "      <td>shampoo</td>\n",
       "      <td>gel</td>\n",
       "      <td>toothpaste</td>\n",
       "      <td>mouthwash</td>\n",
       "      <td>bread</td>\n",
       "      <td>cheese</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mouthwash</td>\n",
       "      <td>toothpaste</td>\n",
       "      <td>soap</td>\n",
       "      <td>shampoo</td>\n",
       "      <td>cheese</td>\n",
       "      <td>yogurt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>razor</td>\n",
       "      <td>mouthwash</td>\n",
       "      <td>soap</td>\n",
       "      <td>butter</td>\n",
       "      <td>bread</td>\n",
       "      <td>cheese</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>shampoo</td>\n",
       "      <td>soap</td>\n",
       "      <td>gel</td>\n",
       "      <td>milk</td>\n",
       "      <td>honey</td>\n",
       "      <td>cereals</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>toothpaste</td>\n",
       "      <td>razor</td>\n",
       "      <td>gel</td>\n",
       "      <td>brush</td>\n",
       "      <td>mouthwash</td>\n",
       "      <td>shampoo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gel</td>\n",
       "      <td>razor</td>\n",
       "      <td>shampoo</td>\n",
       "      <td>milk</td>\n",
       "      <td>cereals</td>\n",
       "      <td>bread</td>\n",
       "      <td>cookies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mouthwash</td>\n",
       "      <td>toothpaste</td>\n",
       "      <td>milk</td>\n",
       "      <td>bread</td>\n",
       "      <td>cookies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0           1        2           3          4           5  \\\n",
       "0   toothpaste       brush     milk     cereals      honey       bread   \n",
       "1         milk     cereals    honey       bread     cheese       razor   \n",
       "2         milk     cereals    honey      cheese       soap     shampoo   \n",
       "3        honey       bread   butter      cheese  mouthwash  toothpaste   \n",
       "4      cereals       honey    bread      butter        gel        soap   \n",
       "5      cheesse      yogurt     milk     cereals      honey     shampoo   \n",
       "6        honey       bread   cheese       razor     butter      yogurt   \n",
       "7        honey       bread   cheese      butter       milk         NaN   \n",
       "8      cereals      butter  cookies       chips        NaN         NaN   \n",
       "9       cerals      cheese   yogurt     cookies      chips         NaN   \n",
       "10  toothpaste       brush      gel     shampoo       soap     cookies   \n",
       "11  toothpaste       brush      gel       razor  mouthwash        milk   \n",
       "12       razor     shampoo      gel        soap      bread      butter   \n",
       "13       brush     shampoo      gel  toothpaste  mouthwash       bread   \n",
       "14   mouthwash  toothpaste     soap     shampoo     cheese      yogurt   \n",
       "15       razor   mouthwash     soap      butter      bread      cheese   \n",
       "16     shampoo        soap      gel        milk      honey     cereals   \n",
       "17  toothpaste       razor      gel       brush  mouthwash     shampoo   \n",
       "18         gel       razor  shampoo        milk    cereals       bread   \n",
       "19   mouthwash  toothpaste     milk       bread    cookies         NaN   \n",
       "\n",
       "          6        7       8  id  \n",
       "0    butter   cheese  yogurt   1  \n",
       "1       gel  shampoo     NaN   2  \n",
       "2       NaN      NaN     NaN   3  \n",
       "3       NaN      NaN     NaN   4  \n",
       "4       NaN      NaN     NaN   5  \n",
       "5       gel      NaN     NaN   6  \n",
       "6       NaN      NaN     NaN   7  \n",
       "7       NaN      NaN     NaN   8  \n",
       "8       NaN      NaN     NaN   9  \n",
       "9       NaN      NaN     NaN  10  \n",
       "10    chips      NaN     NaN  11  \n",
       "11  cookies      NaN     NaN  12  \n",
       "12      NaN      NaN     NaN  13  \n",
       "13   cheese      NaN     NaN  14  \n",
       "14      NaN      NaN     NaN  15  \n",
       "15      NaN      NaN     NaN  16  \n",
       "16      NaN      NaN     NaN  17  \n",
       "17      NaN      NaN     NaN  18  \n",
       "18  cookies      NaN     NaN  19  \n",
       "19      NaN      NaN     NaN  20  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/Users/jiaoyu/Documents/Ph.D/teaching/Machine_learning_with_R/ch9_association_rule/order_data.csv\",delimiter=\" \",header=None)\n",
    "\n",
    "data['id']= range(1, len(data)+1)\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for row in range(0, 20):\n",
    "    data_list.append([str(data.values[row,column]) for column in range(0, 9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['milk', 'cereals', 'honey', 'bread', 'cheese', 'razor', 'gel', 'shampoo'],\n",
       " ['milk', 'cereals', 'honey', 'cheese', 'soap', 'shampoo'],\n",
       " ['honey', 'bread', 'butter', 'cheese', 'mouthwash', 'toothpaste'],\n",
       " ['cereals', 'honey', 'bread', 'butter', 'gel', 'soap'],\n",
       " ['cheesse', 'yogurt', 'milk', 'cereals', 'honey', 'shampoo', 'gel'],\n",
       " ['honey', 'bread', 'cheese', 'razor', 'butter', 'yogurt'],\n",
       " ['honey', 'bread', 'cheese', 'butter', 'milk'],\n",
       " ['cereals', 'butter', 'cookies', 'chips'],\n",
       " ['cerals', 'cheese', 'yogurt', 'cookies', 'chips'],\n",
       " ['toothpaste', 'brush', 'gel', 'shampoo', 'soap', 'cookies', 'chips'],\n",
       " ['toothpaste', 'brush', 'gel', 'razor', 'mouthwash', 'milk', 'cookies'],\n",
       " ['razor', 'shampoo', 'gel', 'soap', 'bread', 'butter'],\n",
       " ['brush', 'shampoo', 'gel', 'toothpaste', 'mouthwash', 'bread', 'cheese'],\n",
       " ['mouthwash', 'toothpaste', 'soap', 'shampoo', 'cheese', 'yogurt'],\n",
       " ['razor', 'mouthwash', 'soap', 'butter', 'bread', 'cheese'],\n",
       " ['shampoo', 'soap', 'gel', 'milk', 'honey', 'cereals'],\n",
       " ['toothpaste', 'razor', 'gel', 'brush', 'mouthwash', 'shampoo'],\n",
       " ['gel', 'razor', 'shampoo', 'milk', 'cereals', 'bread', 'cookies'],\n",
       " ['mouthwash', 'toothpaste', 'milk', 'bread', 'cookies']]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs=[]\n",
    "def remove(the_list, val):\n",
    "    return [value for value in the_list if value != val]\n",
    "for i in range(1, len(data_list)):\n",
    "    bs.append(remove(data_list[i], \"nan\"))\n",
    "bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{butter} -> {bread}, {bread} -> {butter}, {cheese} -> {bread}, {bread} -> {cheese}, {gel} -> {bread}, {bread} -> {gel}, {honey} -> {bread}, {bread} -> {honey}, {razor} -> {bread}, {bread} -> {razor}, {gel} -> {cereals}, {cereals} -> {gel}, {honey} -> {cereals}, {cereals} -> {honey}, {milk} -> {cereals}, {cereals} -> {milk}, {shampoo} -> {cereals}, {cereals} -> {shampoo}, {honey} -> {cheese}, {cheese} -> {honey}, {milk} -> {gel}, {gel} -> {milk}, {razor} -> {gel}, {gel} -> {razor}, {shampoo} -> {gel}, {gel} -> {shampoo}, {milk} -> {honey}, {honey} -> {milk}, {shampoo} -> {milk}, {milk} -> {shampoo}, {toothpaste} -> {mouthwash}, {mouthwash} -> {toothpaste}, {soap} -> {shampoo}, {shampoo} -> {soap}, {milk, shampoo} -> {cereals}, {cereals, shampoo} -> {milk}, {cereals, milk} -> {shampoo}, {shampoo} -> {cereals, milk}, {milk} -> {cereals, shampoo}, {cereals} -> {milk, shampoo}]\n"
     ]
    }
   ],
   "source": [
    "itemsets, rules = apriori(bs, min_support=0.25, min_confidence=0.2)\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
